---
title: "STAT 408 Final Project"
author: "Aaron Myrold, Sathvik Maridasana Nagaraj, Rolando Santos"
date: "2023-11-26"
output: 
  html_document:
    toc: yes
    theme: default
  pdf_document: default
urlcolor: cyan
---

# Bike Sharing Predictive Model

## Introduction

### Source

Our data was found from https://archive.ics.uci.edu/dataset/275/bike+sharing+dataset. This data provides 2 files for data, we will be using the 'day.csv' since every entry is an individual day compared to every hour in the 'hour.csv'.

### Background (From Website)

The dataset contains the hourly and daily count of rental bikes between the years 2011 and 2012 in a Capital bikeshare system with the corresponding weather and seasonal information.

Bike sharing systems are new generation of traditional bike rentals where whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back at another position. Currently, there are about over 500 bike-sharing programs around the world which is composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues. 

Apart from interesting real world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.

With this dataset we want to predict the number of rental bikes would be needed in a given day based on environmental and calendar factors. This would allow the Capital bike sharing system to optimize expected bike maintenance and traffic.

### Research Question

- Can we create a model that will allow us to predict the number of bikes needed on a specific day based on calendar and environmental factors?

### Variables
The dataset has 16 unique variables, however, this study will start off with using 12 of them.

#### Used
- **season**: Season
  + `1`: Winter
  + `2`: Spring
  + `3`: Summer
  + `4`: Fall
- **year**: Year
  + `0`: 2011
  + `1`: 2012
- **mnth**: Month (`1`: January - `12`: December)
- **holiday**: Whether day is holiday or not (`0`: No, `1`: Yes)
- **weekday**: Day of the Week (`0`: Sunday - `6`: Saturday)
- **workingday**: If day is neither weekend nor holiday (`0`: No, `1`: Yes)
- **weathersit**: Weather Situation
  + `1`: Clear
  + `2`: Misty
  + `3`: Snow/Rain
- **temp**: Normalized Temperature in Celsius
- **atemp**: Normalized Feeling Temperature in Celcius
- **windspeed**: Normalized Wind Speed
- **cnt**: Count of total rental bikes including both casual and registered (Response)

#### Unused
- **instant**: Record Index
- **dteday**: Date
- **casual**: Count of Casual Users
- **registered**: Count of Registered Users

The reason why `casual` and `registered` are not used is because they are too closely related to the response `cnt` due to `cnt` being the sum of both variables and can cause issues with our model due to the extremely high correlation.

Each group member will try to fit several models with the price as the response, and a combination of the remaining variables as predictors. The best model fit by each member will be listed below, and will be discussed in the `Results` and `Discussion` sections that follow.

## Methods

```{r echo = FALSE, message = FALSE, warning = FALSE}
# Libraries Used
library(tidyverse)
library(dplyr)
library(forcats)
library(ggplot2)
library(gridExtra)
library(cowplot)
library(carData)
library(corrgram)
library(faraway)
library(caret)
require(MASS)
```

```{r}
# Set seed to ensure you always have same random numbers generated
set.seed(408)  
```

```{r}
# Importing the data
bike_sharing <- read.csv("day.csv")
head(bike_sharing)
```

```{r}
na_count <-sapply(bike_sharing, function(y) sum(is.na(y))) 
na_count <- data.frame(na_count)
na_count
```

There are no missing values in the the dataset.

```{r}
bike_sharing <- bike_sharing[ ,!names(bike_sharing) %in% c("instant", "registered", "dteday", "casual")]
head(bike_sharing)
```

Removed the `instant`, `registered`, `dteday` and `casual` columns from our dataset.

### Helper Functions

```{r}
# Plots "Fitted vs Residual" and "Q-Q" Plots 
plot_diagnostics <- function(m) {
  par(mfrow = c(1, 2))
  plot(fitted(m), resid(m), 
       col = "grey", pch = 20, 
       xlab = "Fitted", ylab = "Residuals", 
       main = "Data from Additive Model")
  abline(h = 0, col = "darkorange", lwd = 2)
  qqnorm(resid(m), main = "Normal Q-Q Plot", col = "darkgrey")
  qqline(resid(m), col = "dodgerblue", lwd = 2)
}

# Create bar plots for categorical vs numeric relationships
create_bp <- function(var, color = "year"){
  bike_sharing %>%
    ggplot(
      aes_string(x = toString(var), y = "cnt", fill = color)
    ) + geom_col(
      position = position_dodge()
    ) + coord_flip()
}

# Create scatter plots for numeric vs numeric relationships
create_sp <- function(var, color = "year"){
  bike_sharing %>%
    ggplot(
      aes_string(x = toString(var), y = "cnt", color = color)
    ) + geom_point()
}

# Calculates NRMSE given "actual" and "predicted values"
get_nrmse <- function(model, data){
  predicted <- (predict(model, data))
  nrmse <- (sqrt(mean((predicted - data$cnt)^2)))/mean(data$cnt)
  return(nrmse)
}

# Get model adjusted r-squared
get_r_squared <- function(model) {
   return(summary(model)$adj.r.squared)
}

# Get max vif
get_max_vif <- function(model) {
  return(max(vif(model)))
}

# Get ANOVA score
get_F_score <- function(m0, m1){
  result <- anova(m0, m1)
  return(result$F[2])
}
```

### Investigation and Variable Relationships

First we will map our categorical variables to their respective descriptions for clarity.

```{r}
bike_sharing <- bike_sharing %>% 
  rename(
    year = yr,
    month = mnth,
  )

bike_sharing <- bike_sharing %>% mutate(
  holiday = fct_recode(as.factor(holiday),
    "No" = "0",
    "Yes" = "1",
  )
) %>% mutate(
  season = fct_recode(as.factor(season),
    "Spring" = "1",
    "Summer" = "2",
    "Fall" = "3",
    "Winter" = "4"
  )
) %>% mutate(
  year = fct_recode(as.factor(year),
    "2011" = "0",
    "2012" = "1"
  )
) %>% mutate(
  month = fct_recode(as.factor(month),
    "January" = "1",
    "February" = "2",
    "March" = "3",
    "April" = "4",
    "May" = "5",
    "June" = "6",
    "July" = "7",
    "August" = "8",
    "September" = "9",
    "October" = "10",
    "November" = "11",
    "December" = "12"
  )
) %>% mutate(
  weekday = fct_recode(as.factor(weekday),
    "Sunday" = "0",
    "Monday" = "1",
    "Tuesday" = "2",
    "Wednesday" = "3",
    "Thursday" = "4",
    "Friday" = "5",
    "Saturday" = "6"
  )
) %>% mutate(
  workingday = fct_recode(as.factor(workingday),
    "No" = "0",
    "Yes" = "1"
  )
) %>% mutate(
  weathersit = fct_recode(as.factor(weathersit),
    "Clear" = "1",
    "Misty" = "2",
    "Snow/Rain" = "3"
  )
)
```

Some plots showing the relationship between the categorical variables and `cnt`.

```{r warning=FALSE}
plot_grid(
  create_bp("season"), 
  create_bp("weathersit"),
  create_bp("month"),
  create_bp("weekday"),
  ncol = 2, nrow = 2)

plot_grid(
  create_sp("temp"), 
  create_sp("atemp"),
  create_sp("hum"),
  create_sp("windspeed"),
  ncol = 2, nrow = 2)
```

Some plots showing the relationship between the numeric variables and `cnt`.

```{r}
#TODO

```

We will also fit a base model to view the current significance of coefficients and to view any constant variance or normality issues.

```{r}
model <- lm(cnt ~ ., data = bike_sharing)
summary(model)
```
One glaring issue with our current base model is that we have a collinearity issue related to `workingday`. Reviewing our variable definitions, `workingday` is directly correlated to whether or not a the current day is neither a weekend or holiday. Thus it would be best to also remove this variable from our model going forward.

```{r}
plot_diagnostics(model)
```

We can see that our data does seem to uphold constant variance, however there appears to be some tail skewedness on our Q-Q plot. Our updated models may resolve this issue.

### Predictive Model Preparation

Since one of the goals of our project is the predict the number of bikes needed for a given day based on provided conditions, it would be best to adjust the categorical variables by turning them into dummy variables/one-hot encoding them.

```{r}
# Creating Dummy Variables
bike_sharing <- fastDummies::dummy_cols(bike_sharing, remove_first_dummy = TRUE)

# Removing the original columns
bike_sharing <- bike_sharing[ ,!names(bike_sharing) %in% c("season", "year", "month", "holiday", "weekday", "workingday", "weathersit")]
head(bike_sharing)
```


We then split the resulting dataset into training and testing datasets, using an 80:20 split.

```{r}
sample_size = floor(0.8 * nrow(bike_sharing)) 
indices = sample(seq_len(nrow(bike_sharing)), size = sample_size)
bike_sharing_trn = bike_sharing[indices,]
bike_sharing_tst = bike_sharing[-indices,]

adj_r_squared <- c()
max_vif <- c()
```

### Models

#### Base Model

This is the initial model similar to the one show above that to used a base comparison for the other models.

```{r}
model0 <- lm(cnt ~ .-workingday_Yes, data = bike_sharing_trn)
```


#### Model 1: AIC

```{r}
model1 <- lm(cnt ~ . -workingday_Yes, data = bike_sharing_trn)
step(model1)
```

```{r}
model1 <- lm(formula = cnt ~ temp + hum + windspeed + season_Summer + season_Fall + 
    season_Winter + year_2012 + month_March + month_April + month_May + 
    month_June + month_July + month_September + month_October + 
    holiday_Yes + weekday_Monday + weekday_Tuesday + weekday_Wednesday + 
    weekday_Thursday + weekday_Friday + weekday_Saturday + weathersit_Misty + 
    `weathersit_Snow/Rain`, data = bike_sharing_trn)
summary(model1)
```

#### Model 2: Transformation

```{r}
#sathvik Model_2
bike_sharing_trn_transformed <- bike_sharing_trn
bike_sharing_tst_transformed <- bike_sharing_tst
 
# Transformation
bike_sharing_trn_transformed$log_temp <- log(bike_sharing_trn_transformed$temp)
bike_sharing_trn_transformed$log_hum <- log(bike_sharing_trn_transformed$hum)
bike_sharing_trn_transformed$log_windspeed <- log(bike_sharing_trn_transformed$windspeed)
bike_sharing_trn_transformed$log_cnt <- log(bike_sharing_trn_transformed$cnt + 1) 

# Doing same for the test set
bike_sharing_tst_transformed$log_temp <- log(bike_sharing_tst_transformed$temp)
bike_sharing_tst_transformed$log_hum <- log(bike_sharing_tst_transformed$hum)
bike_sharing_tst_transformed$log_windspeed <- log(bike_sharing_tst_transformed$windspeed)


# Transformation for the response variable (cnt)
bike_sharing_tst_transformed$log_cnt <- log(bike_sharing_tst_transformed$cnt + 1)

#model with the transformed response variable
model2 <- lm(formula = log_cnt ~ log_temp + log(1 + hum) + log_windspeed + season_Summer + season_Fall + season_Winter + year_2012 + month_February + month_March + month_April + month_May + month_June + month_July + month_August + month_September + month_October + month_November + month_December + holiday_Yes + weekday_Monday + weekday_Tuesday + weekday_Wednesday + weekday_Thursday + weekday_Friday + weekday_Saturday + weathersit_Misty + `weathersit_Snow/Rain`, data = bike_sharing_trn_transformed)
summary(model2)
```

#### Model 3: Correlation Matrix
```{r}
# Compute correlation matrix
correlation_matrix <- cor(bike_sharing_trn)
 
# Identifying pairs of variables with high correlation coefficients
highly_correlated_pairs <- which(correlation_matrix > 0.8 & correlation_matrix < 1, arr.ind = TRUE)
print(highly_correlated_pairs)
 
bike_sharing_trn_corr <- bike_sharing_trn
bike_sharing_trn_corr <- subset(bike_sharing_trn_corr, select = -c(atemp)) # excluded "atemp"

bike_sharing_tst_corr <- bike_sharing_tst
bike_sharing_tst_corr <- subset(bike_sharing_tst_corr, select = -c(atemp))
 
#model without atemp
model3 <- lm(cnt ~ . -workingday_Yes, data = bike_sharing_trn_corr)
summary(model3)
```

#### Model 4: KNN
```{r}
# knn model
factors <- colnames(bike_sharing_trn)[-c(2,5,10,16,19,20,28)]
model4 <- knnreg(bike_sharing_trn[,factors], bike_sharing_trn$cnt, k=9)

# Predict on the TRAIN set and calculate test scores
yhat.train = predict(model4, bike_sharing_trn[,factors])

y.train <- bike_sharing_trn$cnt
MSE.train <- mean((y.train - yhat.train)^2)
MSE.train

RMSE.train <- sqrt(MSE.train)
RMSE.train

NRMSE.train <- RMSE.train / mean(y.train)
NRMSE.train

# Predict on the TEST set and calculate test scores
yhat.test = predict(model4, bike_sharing_tst[,factors])

y.test <- bike_sharing_tst$cnt
MSE.test <- mean((y.test - yhat.test)^2)
MSE.test

RMSE.test <- sqrt(MSE.test)
RMSE.test

NRMSE.test <- RMSE.test / mean(y.test)
NRMSE.test
```

#### Model 5: Ridge Regression
```{r}
library(glmnet)
# Assuming you have a dataframe 'data' with predictors and a response variable 'y'
x <- as.matrix(bike_sharing_trn[, -5])  # predictor variables
y <- bike_sharing_trn$cnt  # response variable

# Scaling the predictor variables
x <- scale(x)

# Fit ridge regression model
# Alpha = 0 indicates ridge regression
ridge_model <- glmnet(x, y, alpha = 0)

# To view the coefficients at different values of lambda
print(coef(ridge_model))

# Cross-validation to find optimal lambda
cv_ridge <- cv.glmnet(x, y, alpha = 0)

# Best lambda
best_lambda <- cv_ridge$lambda.min
print(best_lambda)

# Fit model using the best lambda
final_ridge_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)

# Set test predictor
x.test <- as.matrix(bike_sharing_tst[, -5])  # New predictor variables
x.test <- scale(x.test)  # Don't forget to scale the new predictor variables

# Make predictions
yhat.ridge <- predict(final_ridge_model, x.test)
y.ridge <- bike_sharing_tst$cnt
MSE.ridge <- mean((y.ridge - yhat.ridge)^2)
MSE.ridge

RMSE.ridge <- sqrt(MSE.ridge)
RMSE.ridge

NRMSE.ridge <- RMSE.ridge / mean(y.ridge)
NRMSE.ridge
```

#### Model 6: Transformation + Ridge Regression
```{r}
bs_train_t <- bike_sharing_trn
bs_test_t <- bike_sharing_tst

# Transformation
bs_train_t$cnt.t <- log(bs_train_t$cnt)
bs_test_t$cnt.t <- log(bs_test_t$cnt)

# Assuming you have a dataframe 'data' with predictors and a response variable 'y'
x <- as.matrix(bs_train_t[, -c(2,5,10,16,19,20,28,31)])  # predictor variables
y <- bs_train_t$cnt.t  # response variable

# Scaling the predictor variables
x <- scale(x)

# Fit ridge regression model
# Alpha = 0 indicates ridge regression
ridge_model <- glmnet(x, y, alpha = 0)

# Plotting coefficient paths
plot(ridge_model, xvar = "lambda", label = TRUE)

# To view the coefficients at different values of lambda
print(coef(ridge_model))

# Cross-validation to find optimal lambda
cv_ridge <- cv.glmnet(x, y, alpha = 0)

# Best lambda
best_lambda <- cv_ridge$lambda.min
print(best_lambda)

# Fit model using the best lambda
final_ridge_model <- glmnet(x, y, alpha = 0, lambda = best_lambda)

# Set test predictor
x.test <- as.matrix(bs_test_t[, -c(2,5,10,16,19,20,28,31)])  # New predictor variables
x.test <- scale(x.test)  # Don't forget to scale the new predictor variables

# Make predictions
yhat.trr <- predict(final_ridge_model, x.test)
y.trr <- bs_test_t$cnt.t
MSE.trr <- mean((y.trr - yhat.trr)^2)
MSE.trr

RMSE.trr <- sqrt(MSE.trr)
RMSE.trr

NRMSE.trr <- RMSE.trr / mean(y.trr)
NRMSE.trr

```

## Results

### Plot Diagnostics

#### Base Model

```{r}
plot_diagnostics(model0)
```


#### Model 1: AIC

```{r}
plot_diagnostics(model1)
```

#### Model 2: Transformation

```{r}
plot_diagnostics(model2)
```

#### Model 3: Correlation Matrix

```{r}
plot_diagnostics(model3)

vif_values_model_3 <- car::vif(model3)
vif_values_model_3
#There are some variables with high VIP.
#Trying transformation here too to see if it reduces the VIF
```

#### Model 4: KNN Cross-Validation

```{r}
# randomly shuffle the index
index.random <- sample(1:dim(bike_sharing_trn)[1])

# split the data (index) into 5 folds 
groups <- cut(1:dim(bike_sharing_trn)[1], 5, labels = FALSE)
index.fold <- split(index.random, groups)

MSEs.k <- c()
for(k in 1:20){
  # an empty vector to save individual MSE
  MSEs <- c()
  
  # 5-fold cross-validation
  for(index.test in index.fold){
    
    # creat training and test set
    data.test <- bike_sharing_trn[index.test,]
    data.train <- bike_sharing_trn[-index.test,]
    
    # knn model
    knnmodel <- knnreg(data.train[,factors], data.train$cnt, k = k)
    
    # predict on the test set
    yhat.test = predict(knnmodel, data.test[,factors])
    
    
    # calculate test MSE
    y.test <- data.test$cnt
    MSE.test <- mean((y.test - yhat.test)^2)
    MSEs <- c(MSEs, MSE.test)
  }
  
  # Average 5 MSEs
  MSEs.k <- c(MSEs.k, mean(MSEs))
}

plot(MSEs.k, type='b', col='red', xlab='K', ylab='MSE',)
```

### NMSE Comparison

```{r}
library(knitr)

mod_list = list(model0, model1, model2, model3)
trn_nrmse = c(
  get_nrmse(model0, bike_sharing_trn), 
  get_nrmse(model1, bike_sharing_trn),
  get_nrmse(model2, bike_sharing_trn_transformed),
  get_nrmse(model3, bike_sharing_trn_corr),
  NRMSE.train,
  NA,
  NA
)
tst_nrmse = c(
  get_nrmse(model0, bike_sharing_tst), 
  get_nrmse(model1, bike_sharing_tst),
  get_nrmse(model2, bike_sharing_tst_transformed),
  get_nrmse(model3, bike_sharing_tst_corr),
  NRMSE.test,
  NRMSE.ridge,
  NRMSE.trr
)

nrsme_table = data.frame(
  c("Base Model", "AIC Model", "Transformation Model", "Correlation Model", 'KNN Model', 'Ridge Regression', 'Transform + RR'), trn_nrmse, tst_nrmse)

kable(nrsme_table, format = "markdown", col.names = c("Model", "Training NRMSE", "Testing NRMSE"))
```

### R-Squared and VIF Test

```{r}
# TODO Add ANOVA Scores
F_scores <- c()
for (i in mod_list) {
  if (length(F_scores) == 0){
    F_scores <- append(F_scores, NA)
    next
  }
  F_scores <- append(F_scores, get_F_score(model0, i))
}
rvif_table = data.frame(
  c("Base Model", "AIC Model", "Transformation Model", "Correlation Model"), sapply(mod_list, get_r_squared), sapply(mod_list, get_max_vif), F_scores)

kable(rvif_table, format = "markdown", col.names = c("Model", "Adjusted R-Squared", "Max VIF", 'F-score'))
```

## Discussion

### Plot Diagnostics

Although this study intended to fit a good predictive model, the group members decided that all models must hold for all LINE assumptions, for them to be considered. Looking at the plot diagnostics, we notice the following:

`Model 1`'s Q-Q Plot had an evident tail on the left hand side, which resulted in a violation of the normality assumption. There is not much difference between this plot and the base model's plot

### NRMSE Comparison

TBD

### R-Squared and VIF Test

TBD

## Conclusion

TBD